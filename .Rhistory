# 3D Exploded Pie Chart
library(plotrix)
slices <- c(10, 12, 4, 16, 8)
lbls <- c("US", "UK", "Australia", "Germany", "France")
pie3D(slices,labels=lbls,explode=0.1,
main="Pie Chart of Countries ")
?pie3D
x <- c(4, "a", TRUE)
class(x)
x <- c(1,3, 5)
y <- c(3, 2, 10)
z <- cbind(x, y)
z
x <- list(2, "a", "b", TRUE)
x[[2]]
x <- 1:4
y <- 2:3
x + y
x <- c(17, 14, 4, 5, 13, 12, 10)
x[x > 10] <- 4
x
install.packages(c("colorspace", "data.table", "gstat", "ipred", "maps", "Matrix", "mgcv", "pander", "plotrix", "R.matlab", "R.methodsS3", "R.oo", "R.utils", "rgl", "RgoogleMaps", "rpart", "sp", "spacetime", "stargazer"))
install.packages("C:/Users/woobe/Desktop/mkuhn-parallelrandomforest-1042dda38302.zip", repos = NULL)
sys.info
Sys.info()
sessionInfo()
source('D:/Repo/rfuns/R-benchmark-25-woobe.R')
source('/media/SUPPORT/Repo/rfuns/R-benchmark-25-woobe.R')
install.packages(c("Matrix", "nlme", "rpart"))
detach("package:rpart", unload=TRUE)
install.packages("rpart")
source('D:/Repo/rfuns/R-benchmark-25-woobe.R')
install.packages("D:/Warez/Programming_Tools/R/Packages/Caret/caret_5.17-7.tar.gz", repos = NULL, type = "source")
source('/media/SUPPORT/Repo/rfuns/R-benchmark-25-woobe.R')
library("parallelRandomForest", lib.loc="C:/Revolution/R-Enterprise-7.0/R-3.0.2/library")
source('/media/woobe/SUPPORT/Repo/rfuns/R-benchmark-25-woobe.R')
source('D:/Repo/rfuns/R-benchmark-25-woobe.R')
install.packages("Rserve")
library(Rserve)
Rserve()
SCRIPT_INT(â€˜kmeans(data.frame(.arg1,.arg2,.arg3,.arg4),3)$cluster;', SUM([Petal length]), SUM([Petal width]),SUM([Sepal length]),SUM([Sepal width]))
source('D:/Repo/bib/functions_keypackages.R')
install.packages("devtools")
devtools::install_github("bib", "woobe")
library(bib)
install_key_pkg()
detach("package:rpart", unload=TRUE)
install.packages(c("foreign", "Matrix", "nlme", "rpart", "survival"), lib="C:/Revolution/R-Enterprise-7.0/R-3.0.2/library")
library("rpart", lib.loc="C:/Revolution/R-Enterprise-7.0/R-3.0.2/library")
library(bib)
rm(list=ls())
## Load
suppressMessages(library(bib))
suppressMessages(library(caret))
if (sys_info()[1] == "Linux") {
setwd("/media/SUPPORT/Repo")
} else {
setwd("D:/Repo")
}
## Start ff
start_ff()
data <- quant_create_data(list_symbol, num_sample = 750, num_ahead = 10, num_past = 10)
data_train <- data$train
data_test <- data$test
rm(list=ls())
## Load
suppressMessages(library(bib))
suppressMessages(library(caret))
if (sys_info()[1] == "Linux") {
setwd("/media/SUPPORT/Repo")
} else {
setwd("D:/Repo")
}
## Start ff
start_ff()
rm(list=ls())
## Load
suppressMessages(library(bib))
suppressMessages(library(caret))
if (sys_info()[1] == "Linux") {
setwd("/media/SUPPORT/Repo")
} else {
setwd("D:/Repo")
}
## Start ff
start_ff()
list_symbol = c("AMZN", "NFLX", "GOOG", "YHOO")
data <- quant_create_data(list_symbol, num_sample = 750, num_ahead = 10, num_past = 10)
data_train <- data$train
data_test <- data$test
num_init_trial = 100
num_max_samp = 1000
num_max_mtry = 100
num_ntree = 100
size_perc = seq(0.1, 0.5, 0.1)
num_eval_trial = 100
num_core = 4
verbose = TRUE
data <- quant_create_data(list_symbol, num_sample = 750, num_ahead = 10, num_past = 10)
data_train <- data$train
data_test <- data$test
x <- as.ffdf(data_train[, 2:(ncol(data_train)-1)])
y <- as.matrix(data_train[, ncol(data_train)])
rm(data, list_symbol, data_train)
if (verbose) time_start <- start_timer()
suppressMessages(library("caret"))
suppressMessages(library("randomForest"))
suppressMessages(library("e1071"))
suppressMessages(library("nnet"))
suppressMessages(library("kknn"))
## Mini RF
mini_rf <- function(x, y, num_max_samp, num_max_mtry, num_ntree) {
## Sampling
p_samp <- 0.5
if (nrow(x) > num_max_samp) p_samp <- num_max_samp / nrow(x)
row_samp <- as.integer(createDataPartition(y, p = p_samp, list = F))
## Check mtry
if (is.factor(y)) num_mtry <- floor(ncol(x)/3) else num_mtry <- floor(sqrt(ncol(x)))
num_mtry <- min(c(num_mtry, num_max_mtry))
## Train RF model
model <- randomForest(x[row_samp,], y[row_samp],
mtry = num_mtry,
ntree = num_ntree,
importance = TRUE)
## Return importance
imp <- normalise(as.matrix(model$importance[, 1]))
return(imp)
}
## Mini RF
mini_rf <- function(x, y, num_max_samp, num_max_mtry, num_ntree) {
## Sampling
p_samp <- 0.5
if (nrow(x) > num_max_samp) p_samp <- num_max_samp / nrow(x)
row_samp <- as.integer(createDataPartition(y, p = p_samp, list = F))
## Check mtry
if (is.factor(y)) num_mtry <- floor(ncol(x)/3) else num_mtry <- floor(sqrt(ncol(x)))
num_mtry <- min(c(num_mtry, num_max_mtry))
## Train RF model
model <- randomForest(x[row_samp,], y[row_samp],
mtry = num_mtry,
ntree = num_ntree,
importance = TRUE)
## Return importance
imp <- normalise(as.matrix(model$importance[, 1]))
return(imp)
}
## Run in Parallel
activate_core(num_core, verbose = FALSE)
imp <- foreach(num_model = 1:num_init_trial,
.combine = cbind,
.multicombine = TRUE,
.errorhandling = "remove",
.packages = c("randomForest", "caret", "bib", "ff", "ffbase")) %dopar%
mini_rf(x[,], y, num_max_samp, num_max_mtry, num_ntree)
rm(list=ls())
## Load
suppressMessages(library(bib))
suppressMessages(library(caret))
if (sys_info()[1] == "Linux") {
setwd("/media/SUPPORT/Repo")
} else {
setwd("D:/Repo")
}
## Start ff
start_ff()
list_symbol = c("AMZN", "NFLX", "GOOG", "YHOO")
num_init_trial = 100
num_max_samp = 1000
num_max_mtry = 100
num_ntree = 100
size_perc = seq(0.1, 0.5, 0.1)
num_eval_trial = 100
num_core = 4
verbose = TRUE
data <- quant_create_data(list_symbol, num_sample = 750, num_ahead = 10, num_past = 10)
data_train <- data$train
data_test <- data$test
x <- as.ffdf(data_train[, 2:(ncol(data_train)-1)])
y <- as.matrix(data_train[, ncol(data_train)])
rm(data, list_symbol, data_train)
num_init_trial = 100
num_max_samp = 1000
num_max_mtry = 100
num_ntree = 100
size_perc = seq(0.1, 0.5, 0.1)
num_eval_trial = 100
num_core = 7
verbose = TRUE
if (verbose) time_start <- start_timer()
suppressMessages(library("caret"))
suppressMessages(library("randomForest"))
suppressMessages(library("e1071"))
suppressMessages(library("nnet"))
suppressMessages(library("kknn"))
if (verbose) cat("\n[bib]: Calculating variable importance score ...")
## Mini RF
mini_rf <- function(x, y, num_max_samp, num_max_mtry, num_ntree) {
## Sampling
p_samp <- 0.5
if (nrow(x) > num_max_samp) p_samp <- num_max_samp / nrow(x)
row_samp <- as.integer(createDataPartition(y, p = p_samp, list = F))
## Check mtry
if (is.factor(y)) num_mtry <- floor(ncol(x)/3) else num_mtry <- floor(sqrt(ncol(x)))
num_mtry <- min(c(num_mtry, num_max_mtry))
## Train RF model
model <- randomForest(x[row_samp,], y[row_samp],
mtry = num_mtry,
ntree = num_ntree,
importance = FALSE)
## Return importance
imp <- normalise(as.matrix(model$importance[, 1]))
return(imp)
}
activate_core(num_core, verbose = FALSE)
imp <- foreach(num_model = 1:num_init_trial,
.combine = cbind,
.multicombine = TRUE,
.errorhandling = "remove",
.packages = c("randomForest", "caret", "bib", "ff", "ffbase")) %dopar%
mini_rf(x[,], y, num_max_samp, num_max_mtry, num_ntree)
## De-activate cores
deactivate_core(num_core, verbose = FALSE)
## Get Median
imp_median <- matrix(apply(imp, 1, median), ncol = 1)
## Rank
imp_order <- order(imp_median, decreasing = TRUE)
## Display
if (verbose) {
## Display
cat(" Duration:", stop_timer(time_start), "seconds.\n")
cat("[bib]: Most important variables are:\n\n")
temp_df <- data.frame(variables = matrix(colnames(x)[imp_order], ncol = 1), importance = imp_median[imp_order,])
print(head(temp_df, n = min(c(10, ncol(x)))))
cat("\n")
}
eval_all <- data.frame(matrix(0, nrow = length(size_perc), ncol = 2))
eval_all[, 1] <- round(size_perc * ncol(x))
if (is.factor(y)) {
colnames(eval_all) <- c("num_features",
"acc_median")
} else {
colnames(eval_all) <- c("num_features",
"R2_median")
}
eval_all
p_samp <- 0.5
if (nrow(x) > num_max_samp) p_samp <- num_max_samp / nrow(x)
row_train <- as.integer(createDataPartition(y, p = p_samp, list = F))
row_valid <- as.integer(createDataPartition(y, p = p_samp, list = F))
feature_samp <- c(imp_order[1:num_feature], ncol(x))
num_feature = 26
num_feature = 46
feature_samp <- c(imp_order[1:num_feature], ncol(x))
df_train <- data.frame(x[row_train, feature_samp], y = y[row_train])
df_valid <- data.frame(x[row_valid, feature_samp], y = y[row_valid])
if (is.factor(y)) num_mtry <- floor(ncol(x[, feature_samp])/3) else num_mtry <- floor(sqrt(ncol(x[, feature_samp])))
num_mtry
num_mtry <- min(c(num_mtry, num_max_mtry))
num_mtry
model <- randomForest(x[row_train, feature_samp], y[row_train],
mtry = num_mtry, ntree = num_ntree)
model
yy_rf <- predict(model_rf, y[row_valid]
yy <- predict(model, x[row_valid, feature_samp])
yy
if (is.factor(y)) score <- confusionMatrix(yy, y[row_valid])$overall[1] else score <- R2(yy, y[row_valid])
score
## Mini Eval Function
mini_eval <- function(x, y, num_max_samp, num_max_mtry, num_ntree, imp_order, num_feature) {
## Sampling for training and validation (not extactly OOB but ok for now)
p_samp <- 0.5
if (nrow(x) > num_max_samp) p_samp <- num_max_samp / nrow(x)
row_train <- as.integer(createDataPartition(y, p = p_samp, list = F))
row_valid <- as.integer(createDataPartition(y, p = p_samp, list = F))
## Extract Features
feature_samp <- c(imp_order[1:num_feature], ncol(x))
## Create temporary df
df_train <- data.frame(x[row_train, feature_samp], y = y[row_train])
df_valid <- data.frame(x[row_valid, feature_samp], y = y[row_valid])
## Train and Evaluate RF model
if (is.factor(y)) num_mtry <- floor(ncol(x[, feature_samp])/3) else num_mtry <- floor(sqrt(ncol(x[, feature_samp])))
num_mtry <- min(c(num_mtry, num_max_mtry))
model <- randomForest(x[row_train, feature_samp], y[row_train],
mtry = num_mtry, ntree = num_ntree)
yy <- predict(model, x[row_valid, feature_samp])
if (is.factor(y)) score <- confusionMatrix(yy, y[row_valid])$overall[1] else score <- R2(yy, y[row_valid])
## Return
return(score)
}
num_size =1
time_start <- start_timer()
num_feature <- round(size_perc * ncol(x))[num_size]
if (verbose) cat("[bib]: Evaluating the most important", num_feature, "features ...")
activate_core(num_core, FALSE)
eval_temp <- foreach(num_model = 1:num_eval_trial,
.combine = rbind,
.multicombine = TRUE,
.errorhandling = "remove",
.packages = c("randomForest", "caret", "ff", "ffbase")) %dopar%
mini_eval(x[,], y, num_max_samp, num_max_mtry, num_ntree, imp_order, num_feature)
eval_temp
eval_all[num_size, -1] <- median(eval_temp)
eval_all
if (verbose) {
if (is.factor(y)) {
cat(" Median OOB Accuracy:", round(median(eval_temp), digits = 3),
"... Duration:", stop_timer(time_start), "seconds.\n")
} else {
cat(" Median OOB R-squared:", round(median(eval_temp), digits = 3),
"... Duration:", stop_timer(time_start), "seconds.\n")
}
source('/media/SUPPORT/Repo/bib/R/select_feature3.r')
install.packages("domino", contriburl="http://help.dominoup.com/assets/R/src/contrib", type="source")
library("domino", lib.loc="/home/woobe/R/x86_64-pc-linux-gnu-library/3.0")
domino.login("woobe", "rhine8e")
library(domino)
domino.login("woobe", "rhine8e")
library(domino)
domino.login("yourUsername", "yourPassword")
domoino
domino
domino.login
domino.login("woobe", "rhine8e")
domino.login("woobe1208@gmail.com", password="rhine8e")
install.packages("domino", contriburl="http://help.dominoup.com/assets/R/src/contrib", type="source")
library(domino)
domino.login("woobe", "rhine8e")
install.packages("domino", contriburl="http://help.dominoup.com/assets/R/src/contrib", type="source")
install.packages("domino", contriburl = "http://help.dominoup.com/assets/R/src/contrib",
install.packages("domino", contriburl="http://help.dominoup.com/assets/R/src/contrib", type="source")
library("domino", lib.loc="/home/woobe/R/x86_64-pc-linux-gnu-library/3.0")
domino.login("woobe","rhine8e")
remove.packages("domino")
install.packages("domino", contriburl="http://help.dominoup.com/assets/R/src/contrib", type="source")
install.packages("domino", contriburl = "http://help.dominoup.com/assets/R/src/contrib",
type = "source")
library("domino", lib.loc="/home/woobe/R/x86_64-pc-linux-gnu-library/3.0")
library(domino)
domino.login("woobe1208@gmail.com", "rhine8e")
domino.login()
domino.get("quick-start")
source('/media/SUPPORT/Repo/bib_slidify/run.r')
svm(x, y, ...)
randomForest(x, y, ...)
source('/media/SUPPORT/Repo/bib_slidify/run.r')
source('~/.active-rstudio-document', echo=TRUE)
source('/media/SUPPORT/Repo/bib_slidify/run.r')
